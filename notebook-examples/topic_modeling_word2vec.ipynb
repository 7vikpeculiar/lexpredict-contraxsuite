{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Standard imports\n",
    "import os\n",
    "import string\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup path\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../contraxsuite_services/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Django imports\n",
    "import django\n",
    "from django.db import IntegrityError\n",
    "\n",
    "# Setup django environment\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"config.settings.local\")\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import document model\n",
    "from contraxsuite_services.apps.document import *\n",
    "from contraxsuite_services.apps.task.utils.nlp import *\n",
    "from contraxsuite_services.apps.task.utils.text import *\n",
    "from contraxsuite_services.apps.task.tasks import normalize, stem_tokens, stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data science imports\n",
    "import gensim\n",
    "import gensim.corpora\n",
    "import gensim.models\n",
    "import gensim.models.word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sentence sample list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training sample\n",
    "sentence_list = []\n",
    "\n",
    "# Iterate and print\n",
    "for d in Document.objects.all()[0:50]:\n",
    "    for tu in d.textunit_set.filter(unit_type=\"sentence\").order_by(\"id\").all():\n",
    "        sentence_list.append(normalize(tu.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-01 18:53:48,510 [MainThread  ] [INFO ]  collecting all words and their counts\n",
      "2017-08-01 18:53:48,512 [MainThread  ] [INFO ]  PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-08-01 18:53:48,555 [MainThread  ] [INFO ]  PROGRESS: at sentence #10000, processed 240306 words, keeping 5640 word types\n",
      "2017-08-01 18:53:48,573 [MainThread  ] [INFO ]  collected 6887 word types from a corpus of 337241 raw words and 14126 sentences\n",
      "2017-08-01 18:53:48,574 [MainThread  ] [INFO ]  Loading a fresh vocabulary\n",
      "2017-08-01 18:53:48,582 [MainThread  ] [INFO ]  min_count=5 retains 2560 unique words (37% of original 6887, drops 4327)\n",
      "2017-08-01 18:53:48,583 [MainThread  ] [INFO ]  min_count=5 leaves 329967 word corpus (97% of original 337241, drops 7274)\n",
      "2017-08-01 18:53:48,590 [MainThread  ] [INFO ]  deleting the raw counts dictionary of 6887 items\n",
      "2017-08-01 18:53:48,591 [MainThread  ] [INFO ]  sample=0.001 downsamples 48 most-common words\n",
      "2017-08-01 18:53:48,592 [MainThread  ] [INFO ]  downsampling leaves estimated 230248 word corpus (69.8% of prior 329967)\n",
      "2017-08-01 18:53:48,593 [MainThread  ] [INFO ]  estimated required memory for 2560 words and 100 dimensions: 3328000 bytes\n",
      "2017-08-01 18:53:48,599 [MainThread  ] [INFO ]  resetting layer weights\n",
      "2017-08-01 18:53:48,630 [MainThread  ] [INFO ]  training model with 3 workers on 2560 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-08-01 18:53:49,623 [MainThread  ] [INFO ]  worker thread finished; awaiting finish of 2 more threads\n",
      "2017-08-01 18:53:49,625 [MainThread  ] [INFO ]  worker thread finished; awaiting finish of 1 more threads\n",
      "2017-08-01 18:53:49,629 [MainThread  ] [INFO ]  worker thread finished; awaiting finish of 0 more threads\n",
      "2017-08-01 18:53:49,630 [MainThread  ] [INFO ]  training on 1686205 raw words (1151707 effective words) took 1.0s, 1156651 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "word2vec_model = gensim.models.word2vec.Word2Vec(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2560"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show vocabulary size\n",
    "len(word2vec_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the vector for the concept \"assign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26161176, -0.16407771, -0.40077955, -0.12600055,  0.41745022,\n",
       "       -0.07047732,  0.64792246, -0.71008027, -0.08653647, -0.46014813,\n",
       "       -0.18735853,  0.31150085,  0.12557301, -0.01342526,  0.00387105,\n",
       "       -0.14358574,  0.26174042,  0.11262165, -0.12912995,  0.75031877,\n",
       "        0.1266973 ,  0.56346273,  0.16052081,  1.20694351,  0.22862051,\n",
       "        0.5383721 ,  0.86124098,  0.69743252, -0.14519298, -0.27886057,\n",
       "        0.06332136, -0.02382321, -0.1628231 ,  0.44388682, -0.5663746 ,\n",
       "        0.26292726, -0.83798271, -0.45327497,  0.08511386, -0.56426793,\n",
       "        0.36550534, -0.57639825, -0.44245222, -0.42558497,  1.03601384,\n",
       "       -0.47760651,  0.25984782, -0.29440579,  0.91382223,  0.0812201 ,\n",
       "        0.16682558,  0.95292634,  0.59663928,  0.86263126, -0.3458392 ,\n",
       "       -1.18008697, -0.17823279,  0.35147128,  0.23613958,  0.35853672,\n",
       "        0.12772545,  0.13320085, -0.24835874, -0.45698234, -0.21994391,\n",
       "        0.05583423,  0.64813834,  0.12949063, -0.10010085, -0.6802724 ,\n",
       "        0.65461856, -0.36140689,  0.19273566,  0.11258803, -0.18788213,\n",
       "        0.3572782 , -0.63552749, -0.49897903,  0.2746183 ,  0.9571498 ,\n",
       "        0.11667961,  0.20325959,  0.09282517, -0.49197045,  0.60461754,\n",
       "       -0.2431246 , -0.75746739,  0.26137918,  0.25432536, -0.45914596,\n",
       "       -0.16762401,  0.52933991, -0.24773555, -0.01076578, -0.01581261,\n",
       "       -0.24263881,  0.86748344, -0.61938006,  0.93924981,  0.48518369], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv[stemmer.stem(\"assign\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-01 18:53:49,653 [MainThread  ] [INFO ]  precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'memorandum'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.doesnt_match([stemmer.stem(\"purchase\"), \n",
    "                                stemmer.stem(\"sell\"),\n",
    "                                stemmer.stem(\"transfer\"),\n",
    "                               stemmer.stem(\"memorandum\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paid', 0.8569889068603516),\n",
       " ('escrow', 0.7999917268753052),\n",
       " ('purchas', 0.7718213796615601),\n",
       " ('us', 0.7551891803741455),\n",
       " ('issu', 0.7367774844169617),\n",
       " ('prefer', 0.7355434894561768),\n",
       " ('common', 0.7233516573905945),\n",
       " ('citizen', 0.7217422723770142),\n",
       " ('agent', 0.7140426635742188),\n",
       " ('proportion', 0.7114315032958984)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar(positive=[stemmer.stem(\"stock\"), stemmer.stem(\"option\"), stemmer.stem(\"corporation\")],\n",
    "                               negative=[stemmer.stem(\"partnership\")])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
